{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from icecream import ic\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "with open(\"../BERT-base_mecab-ipadic-bpe-32k/vocab.txt\",  \"r\", encoding=\"utf-8\" ) as f:\n",
    "    vocab = f.read()\n",
    "    for id, word in enumerate(vocab.split('\\n')):\n",
    "        dic[word] = id\n",
    "        \n",
    "text = \"[CLS] 私 は 犬 が 好き 。 [SEP]\"\n",
    "\n",
    "x = [dic[w] for w in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(x).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = bert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2636e-01, -1.2734e-01,  4.1125e-01, -3.7946e-02,  3.5671e-01,\n",
       "         5.9472e-01, -1.2080e-02, -2.0193e-01,  6.1377e-01,  2.1312e-01,\n",
       "        -7.4529e-02,  2.0608e-02, -4.5949e-01,  2.5509e-01, -2.4717e-01,\n",
       "        -9.4191e-02,  1.1410e-01, -2.2248e-01,  3.5165e-01,  4.6572e-01,\n",
       "        -3.8768e-01, -8.5532e-02,  2.5526e-01,  2.6166e-01, -3.1824e-01,\n",
       "         8.1794e-02, -2.4993e-01,  2.9269e-01,  7.9955e-01,  3.5923e-01,\n",
       "        -1.2338e-01,  6.5812e-03,  3.8730e-01,  2.3091e-01,  1.4636e-01,\n",
       "         4.6668e-01,  2.6290e-01,  1.6372e-01,  6.9316e-02,  1.4958e-01,\n",
       "        -5.9775e-01,  2.1966e-01, -1.5152e-01, -7.7528e-03,  2.8760e-02,\n",
       "         8.2232e-01, -2.1874e-01,  4.2410e-02,  8.8731e-01,  9.9789e-02,\n",
       "        -6.2738e-01, -4.2279e-01,  9.3123e-03, -3.0431e-01, -2.4775e-01,\n",
       "        -9.0133e-02,  1.4442e+00,  2.2802e-01,  4.4458e-01, -3.1874e-01,\n",
       "        -6.9717e-01,  6.2764e-01, -3.7871e-02, -6.9396e-02,  1.3187e-01,\n",
       "        -1.4630e-01, -9.5384e-02, -4.0134e-02, -1.1419e+00,  5.0267e-01,\n",
       "        -5.0180e-01,  6.6902e-01, -8.6004e-01, -2.8318e-02,  2.4716e-01,\n",
       "         5.5095e-01, -2.2537e-01,  1.9594e-01,  2.7266e-01, -3.5039e-01,\n",
       "        -2.2121e-01, -4.8057e-02,  2.1614e-01,  3.7493e-01,  1.5255e-01,\n",
       "        -2.2028e-02, -7.3651e-01,  5.6596e-01, -1.2990e-01, -2.1525e-01,\n",
       "         4.9725e-01,  3.2755e-01,  1.4070e-01, -1.4203e-01, -3.0324e-01,\n",
       "         4.9558e-01, -2.0771e-01, -4.6211e-01,  1.1700e-01,  4.6133e-03,\n",
       "        -7.4607e-01, -7.8644e-01,  4.3173e-01, -7.4613e-01,  5.7458e-02,\n",
       "        -6.4743e-03, -5.6369e-01,  3.6449e-01,  2.7439e-01,  4.5760e-01,\n",
       "         1.3098e-01,  7.3430e-01,  3.4693e-01, -9.2957e-02,  2.2157e-01,\n",
       "        -5.9410e-01, -3.3102e-01,  4.8622e-02,  3.9111e-01,  2.0070e-01,\n",
       "         1.2561e-01,  2.8281e-01,  5.6432e-01,  2.8840e-01, -1.3205e-01,\n",
       "        -1.6940e-01,  1.1061e+00, -4.8166e-01, -7.7946e-02, -4.8893e-01,\n",
       "        -4.7354e-02, -7.6424e-01, -9.1521e-01,  4.7544e-01, -3.2645e-01,\n",
       "         2.8502e-01, -3.3783e-02,  7.2673e-01, -3.5925e-01, -2.1302e-01,\n",
       "         3.1164e-01,  2.7859e-01,  9.4417e-01,  4.2333e-01,  8.9327e-01,\n",
       "        -2.9452e-01,  6.2696e-01, -6.7386e-02,  1.7236e-01, -4.0853e-01,\n",
       "         4.3754e-01,  2.2073e-01, -7.0428e-01, -1.1578e-01, -2.6477e-01,\n",
       "        -4.3494e-01, -6.9601e-01, -5.0655e-01,  5.9983e-01,  1.0477e+00,\n",
       "        -7.3032e-01,  3.4891e-01, -1.9410e-01,  5.7067e-02,  4.9292e-01,\n",
       "        -3.2191e-01, -3.6206e-01,  6.9024e-01, -1.8361e-01,  8.5708e-02,\n",
       "         9.0006e-02,  4.2827e-01, -1.7562e-01, -1.1233e-02, -4.9506e-01,\n",
       "         3.5904e-01,  2.4320e-01,  1.8439e-01, -1.8764e-01, -1.9291e-01,\n",
       "        -4.6769e-01,  3.3824e-02,  1.7553e-01, -5.8764e-01, -2.7029e-01,\n",
       "         4.9463e-01, -7.9573e-01,  4.0490e-01, -1.6254e-01,  2.5074e-01,\n",
       "         4.5026e-01,  5.9887e-01,  4.5802e-01, -6.8991e-01, -1.1518e-01,\n",
       "        -7.1103e-02,  4.3074e-01,  1.2597e-01, -1.7785e-02,  1.3623e-01,\n",
       "         1.4732e-01, -1.4807e-02,  1.8128e-01,  1.3673e-01,  4.8054e-02,\n",
       "         9.2967e-01,  5.2012e-02, -1.2880e-01, -5.5237e-02,  2.6225e-01,\n",
       "         5.6227e-02, -7.2467e-03,  3.8972e-02, -8.8316e-02,  8.3572e-02,\n",
       "        -4.1377e-01, -5.0239e-03,  2.6995e-01, -8.7080e-02,  2.5820e-01,\n",
       "         8.8450e-02,  4.4651e-01,  7.7217e-01,  5.7551e-03,  4.0472e-01,\n",
       "         5.5931e-02,  8.5114e-01, -5.7391e-01,  1.6231e-01, -4.9489e-02,\n",
       "        -2.2377e-01, -4.7706e-01,  5.2503e-01, -1.6769e-01, -9.1922e-02,\n",
       "         3.7336e-01, -3.5309e-01,  7.0598e-01,  3.9674e-01, -5.3772e-02,\n",
       "         6.9892e-01, -1.5170e-01, -1.9310e-01,  3.7981e-01, -7.6653e-01,\n",
       "        -3.5357e-01, -1.2882e-02, -3.1287e-02, -5.5400e-01,  3.6271e-01,\n",
       "         1.2920e-01,  2.1026e-01, -3.9403e-01, -4.6997e-02, -4.6301e-01,\n",
       "        -5.4901e-01,  3.6518e-01, -1.3955e+00,  5.5823e-02,  6.5063e-01,\n",
       "        -3.1004e-03,  3.7068e-02, -3.9735e-01,  7.0079e-02, -7.7613e-01,\n",
       "        -1.8507e-01, -2.9915e-01,  6.3105e-01, -2.1384e-01,  4.7937e-01,\n",
       "        -3.0145e-02, -1.0822e-01,  3.3522e-01,  5.3279e-01, -3.9141e-01,\n",
       "        -2.5561e-01, -6.2588e-01, -3.5809e-01,  6.3246e-01,  1.7020e-01,\n",
       "        -5.3728e-03, -1.5626e-01, -1.5021e+00, -4.9895e-01, -4.2466e-02,\n",
       "         8.3843e-01,  4.7990e-02, -5.1288e-02, -2.7274e-01, -6.2329e-01,\n",
       "        -8.6088e-02,  4.1608e-01,  1.1139e-01,  3.4601e-01,  9.7202e-01,\n",
       "         2.0434e-01, -2.3330e-01,  8.2589e-03, -1.0363e-01,  8.6864e-02,\n",
       "         1.7144e-01, -4.5553e-03,  2.9243e-02,  1.4029e-01,  1.9651e-01,\n",
       "         1.3921e-02, -8.1708e-01,  4.2241e-01,  7.6434e-01,  8.5447e-02,\n",
       "        -2.4554e-01,  6.1175e-01,  3.1224e-01,  7.4443e-01,  2.6618e-01,\n",
       "        -3.2915e-01,  1.9511e-01,  2.8974e-01,  4.1188e-01,  1.0091e-01,\n",
       "        -5.6285e-01, -3.0537e-01, -4.6778e-01,  2.2863e-01,  9.7901e-04,\n",
       "        -5.3482e-01,  1.9482e-01, -1.4910e-02, -2.8754e-01,  1.5458e-01,\n",
       "        -1.9697e-01,  2.3194e-01, -4.5634e-01, -9.4692e-02, -4.7934e-01,\n",
       "        -4.4342e-01,  1.3820e-01,  2.7414e-01, -1.8712e-02, -1.9631e-01,\n",
       "         1.0009e-01,  7.8175e-01, -3.9911e-02,  9.0097e-01, -4.5911e-01,\n",
       "        -1.5239e-01, -3.2153e-02,  1.9477e-01, -2.3704e-01,  1.0202e-03,\n",
       "         6.4125e-01,  2.5652e-01,  1.1754e-01, -6.6058e-01, -1.4489e-01,\n",
       "         5.1765e-02,  5.1428e-01, -4.5977e-01,  1.3868e-01,  1.0421e-01,\n",
       "        -2.9658e-02,  2.8779e-01,  6.9075e-01,  5.4622e-01, -6.3122e-01,\n",
       "        -7.2606e-02, -7.9440e-01, -2.0620e-01, -4.2225e-01, -1.6070e-01,\n",
       "        -8.6649e-02,  1.4101e-01, -7.5491e-01,  1.0600e-01,  2.4214e-01,\n",
       "        -5.3326e-01, -6.1987e-01, -3.4620e-01,  1.5708e-01, -1.4969e-01,\n",
       "         3.6526e-01, -1.8333e-01, -5.9828e-01, -3.4726e-01, -2.9197e-01,\n",
       "        -3.8246e-01,  2.4109e-01,  8.2283e-02,  1.8602e-01,  3.7789e-01,\n",
       "        -6.1797e-02,  3.6415e-02, -4.1763e-01, -1.1590e-01,  2.4209e-01,\n",
       "         3.5159e-01, -2.3424e-01, -2.0255e-01,  2.8956e-01,  7.0934e-03,\n",
       "        -4.4297e-01, -4.4249e-02, -3.1908e-01,  3.1051e-02,  4.8135e-01,\n",
       "         2.4680e-01,  2.7877e-01, -3.7734e-01, -1.0593e-01,  1.6187e-01,\n",
       "         5.0757e-01, -1.0019e+00, -8.7185e-02,  2.9606e-01,  1.3530e-02,\n",
       "         8.6630e-02,  3.3357e-01, -7.5095e-01, -2.1433e-02, -5.4963e-01,\n",
       "         3.1206e-01, -5.5403e-02, -1.0946e+00,  1.3473e-01,  3.9708e-01,\n",
       "         2.7739e-01, -4.6436e-01, -5.4644e-02, -3.9295e-01, -1.2051e-01,\n",
       "        -3.2665e-01, -1.0662e-03,  5.2600e-02,  3.5859e-01, -2.0447e-01,\n",
       "         1.0261e+00,  6.0770e-01, -6.9690e-01, -4.3956e-01,  8.3881e-01,\n",
       "         7.7650e-01,  1.4149e-01, -1.2465e-01,  4.8639e-01, -3.6845e-01,\n",
       "        -3.9505e-01, -2.2520e-01,  7.1529e-01, -1.2594e-01, -3.9724e-01,\n",
       "        -2.9168e-01, -6.2677e-01, -3.3448e-01,  5.9854e-01,  2.0486e-01,\n",
       "         3.9802e-01,  1.2763e-01, -5.7305e-01,  2.1901e-01,  1.2301e-01,\n",
       "        -4.7575e-01,  4.0336e-01,  2.2059e-01, -3.4848e-02, -3.1772e-01,\n",
       "         7.4034e-02, -9.9276e-02, -6.3303e-02,  6.7730e-01, -7.9260e-01,\n",
       "        -4.5202e-02,  5.2365e-01, -2.7718e-02,  5.9223e-03, -9.1440e-02,\n",
       "         6.5027e-01,  5.0533e-01,  3.6670e-02,  6.4551e-01,  1.9206e-03,\n",
       "        -8.6307e-02, -7.2769e-02, -2.6181e-01,  2.8473e-01, -8.0327e-01,\n",
       "         1.6735e-01,  7.1643e-01,  3.0394e-01, -4.1841e-01,  4.9319e-01,\n",
       "         4.9865e-01,  4.2977e-01,  2.0655e-01, -6.0212e-01, -1.8473e-01,\n",
       "         1.1200e-02,  1.9169e-01, -3.7922e-01,  5.0830e-02,  1.4850e-01,\n",
       "         5.5978e-01,  3.6470e-01,  7.7679e-02, -3.8389e-01, -4.8850e-01,\n",
       "         2.3830e-01,  3.9645e-01, -8.9931e-01, -1.8844e-01, -2.7444e-01,\n",
       "         1.8547e-01,  2.4568e-01, -2.1540e-01, -2.8980e-02,  5.0126e-01,\n",
       "        -5.6360e-01, -2.7866e-01, -1.9295e-01,  9.1583e-01, -3.0396e-01,\n",
       "        -1.7067e-01, -1.2645e-01, -4.1039e-01, -9.2601e-02, -2.6981e-01,\n",
       "         1.2651e-01,  5.6678e-01,  1.9600e-01, -2.8665e-01,  4.0650e-01,\n",
       "         1.2173e-01, -1.7194e-01,  8.4419e-01,  3.3347e-01,  4.3319e-02,\n",
       "         1.3786e-02, -1.6547e-01, -5.3772e-01,  2.0879e-01,  2.2129e-01,\n",
       "         6.6415e-02, -1.2108e-01,  6.2374e-01, -5.7487e-01,  9.1839e-01,\n",
       "        -6.1932e-01, -8.0079e-02, -2.3511e-01,  3.1379e-01,  4.0686e-01,\n",
       "         2.8223e-01, -5.3857e-01, -2.6997e-01, -7.6706e-02, -2.8245e-01,\n",
       "        -2.6830e-01, -4.4252e-01,  2.3550e-01, -8.6242e-01,  2.1785e-02,\n",
       "        -1.3134e-01,  9.0185e-02, -1.0116e-01,  2.9397e-01, -6.3964e-03,\n",
       "        -5.5898e-01,  1.2330e-01, -6.4213e-01,  2.6501e-01, -1.6842e-02,\n",
       "        -4.7033e-01,  1.7309e-01, -5.6419e-02,  5.7463e-01, -7.6251e-01,\n",
       "         1.6844e-01, -1.1225e-01,  3.3626e-01,  4.9026e-02, -2.5254e-01,\n",
       "         1.6437e-01,  5.5116e-01, -5.1896e-01,  5.4747e-02, -5.2932e-01,\n",
       "         3.6159e-01,  7.1701e-01, -1.7432e-01, -4.3881e-01, -3.2366e-01,\n",
       "        -5.0767e-01, -2.0115e-01, -2.2987e-01, -4.9926e-01,  5.8573e-01,\n",
       "         3.9168e-01,  2.9184e-01, -7.7926e-01,  2.4396e-01, -2.0216e-01,\n",
       "        -4.8349e-01,  1.2666e-01,  5.7137e-01,  3.6593e-01,  2.5444e-01,\n",
       "        -3.8959e-01,  1.4999e-01, -7.0352e-01,  2.5381e-01,  1.3579e-01,\n",
       "         4.2275e-01, -6.3476e-01, -1.6673e-01, -7.6727e-02,  5.0017e-01,\n",
       "        -1.3614e+00,  1.7419e-01, -1.1971e-01,  3.5219e-01,  2.5904e-01,\n",
       "         9.0094e-02,  8.5215e-01, -2.4464e-01,  3.9043e-01,  9.1599e-01,\n",
       "         2.2390e-01,  2.3598e-02, -9.1799e-01, -3.8023e-02, -1.1525e-01,\n",
       "         9.5774e-02, -4.0080e-02,  5.8575e-01, -5.8251e-01,  3.8501e-03,\n",
       "        -7.6207e-01, -7.1315e-02, -2.6048e-01,  3.2383e-01, -7.0393e-01,\n",
       "         5.1572e-01, -1.7971e-01, -1.0781e-01, -2.4707e-01, -4.3959e-02,\n",
       "        -5.0989e-02,  5.9210e-01, -1.5463e-02, -1.4231e-01, -2.3543e-01,\n",
       "         2.3660e-01, -3.6423e-01, -6.1305e-02, -4.9595e-01,  1.1677e-01,\n",
       "        -6.2476e-03, -4.6197e-02,  8.3986e-02,  7.9944e-02,  2.1710e-01,\n",
       "         6.3772e-01,  1.9252e-01,  1.1059e-01,  1.2271e-01, -2.7933e-01,\n",
       "         2.7812e-01, -3.0458e-01, -3.6236e-01, -9.9733e+00,  5.3445e-01,\n",
       "        -6.1084e-01,  3.5478e-01, -4.4430e-01,  2.0473e-01,  4.9334e-01,\n",
       "         3.0226e-01,  4.9448e-01,  1.9301e-01,  1.4200e-01, -6.0790e-02,\n",
       "        -6.7130e-02, -2.9199e-01, -5.6820e-01,  8.4747e-01, -4.0862e-01,\n",
       "        -2.3701e-01,  8.0204e-01, -4.0005e-01, -8.3642e-01, -3.4560e-01,\n",
       "        -3.7893e-01,  3.7334e-01,  8.7733e-02,  8.1779e-02, -9.3863e-01,\n",
       "        -8.8667e-02, -2.5217e-01,  1.8868e-01, -3.3601e-01,  2.4337e-01,\n",
       "        -9.0584e-01, -2.7559e-01, -2.9569e-01, -1.2442e-01,  2.8073e-01,\n",
       "         4.0143e-01,  2.0874e-01,  4.8844e-01, -3.7374e-01, -1.7950e-01,\n",
       "        -6.7642e-02, -1.0630e+00,  6.5236e-01, -2.8368e-01,  4.4323e-01,\n",
       "         6.4191e-02,  2.3430e-01, -3.6649e-02, -1.5684e-01, -2.6421e-01,\n",
       "        -3.6368e-01, -6.9880e-01, -1.6153e-01, -1.8823e-01,  4.6617e-02,\n",
       "         9.3144e-02,  1.0430e-02,  6.0366e-01,  2.8327e-01,  1.1565e-01,\n",
       "        -8.7768e-02,  4.7500e-01, -2.3949e-01,  5.8169e-01,  2.5403e-01,\n",
       "         4.1323e-01, -7.0600e-01,  4.1934e-01,  1.0501e-01,  9.9605e-02,\n",
       "         7.5673e-02,  5.1302e-01, -2.6561e-01, -5.4856e-01, -7.2084e-01,\n",
       "        -3.3494e-01,  8.0041e-01,  9.5123e-02, -4.3697e-01, -2.6048e-01,\n",
       "        -7.0522e-01,  2.9933e-01,  2.2629e-01, -9.8538e-02,  3.0781e-01,\n",
       "        -2.2554e-01,  5.4424e-01, -3.6351e-01,  1.6985e-01,  4.8340e-01,\n",
       "        -3.1554e-01,  5.9462e-02, -5.6606e-01,  1.9571e-01,  3.2333e-01,\n",
       "         3.6122e-01, -2.9694e-01, -3.1038e-01], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer\n",
    "\n",
    "tknz = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['私', 'は', '犬', 'が', '好き']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknz.tokenize(\"私は犬が好き\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = tknz.encode(\"私は[MASK]が好き\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertForMaskedLM\n",
    "\n",
    "# model = BertForMaskedLM.from_pretrained('cl-tohoku/bert-base-japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = model(torch.LongTensor(ids).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mskpos = 3\n",
    "# b=torch.topk(a[0][0][mskpos], k=5)\n",
    "# tknz.convert_ids_to_tokens(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = [],[]\n",
    "y_train, y_test = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train_twitterJSA_data.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"../data/test_twitterJSA_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = train_df[\"label\"].tolist()\n",
    "# y_test = test_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8320501d7e20484cb752326c4154dc29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1841495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in tqdm(range(len(train_df))):\n",
    "#     print(ind)\n",
    "    \n",
    "    if type(train_df[\"text\"].iloc[ind]  ) != str:\n",
    "        continue\n",
    "    tid = tknz.encode(train_df[\"text\"].iloc[ind]) \n",
    "    \n",
    "    if (len(tid)>512):\n",
    "        tid = tid[:512]\n",
    "    x_train.append(tid)\n",
    "    y_train.append(train_df[\"label\"].iloc[ind])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(x_train[1])\n",
    "\n",
    "# net(torch.LongTensor(x_train[1]).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    if (len(x_train[i])) < 2:\n",
    "        print(x_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d41aba2bef4d4699d674edfed0ab42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=107004.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in tqdm(range(len(test_df))):\n",
    "    \n",
    "    if type(test_df[\"text\"].iloc[ind]  ) != str:\n",
    "        continue\n",
    "    tid = tknz.encode(test_df[\"text\"].iloc[ind]) \n",
    "    if (len(tid)>512):\n",
    "        tid = tid[:512]\n",
    "    x_test.append(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b964dacfaea340ba8c5a7afbddc2d463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=107004.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in tqdm(range(len(test_df))):\n",
    "    \n",
    "    if type(test_df[\"text\"].iloc[ind] ) != str:\n",
    "        continue\n",
    "    \n",
    "    tid = tknz.encode(test_df[\"text\"].iloc[ind]) \n",
    "    if (len(tid)>512):\n",
    "        tid = tid[:512]\n",
    "    x_test.append(tid)\n",
    "    y_test.append(test_df[\"label\"].iloc[ind])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocCls(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(DocCls, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.cls = nn.Linear(768, 5)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        bout = self.bert(input_ids=x1, attention_mask=x2)\n",
    "        bs = len(bout[0])\n",
    "        h0 = [bout[0][i][0] for i in range(bs)]\n",
    "        h0 = torch.stack(h0, dim=0)\n",
    "        return self.cls(h0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "net = DocCls(bert)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a841c966cf2c449eb3c463705f3b8eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.6952499151229858\n",
      "0 100 108.38530361652374\n",
      "0 200 104.05317866802216\n",
      "0 300 104.74666285514832\n",
      "0 400 100.43070149421692\n",
      "0 500 93.01586627960205\n",
      "0 600 96.6485664844513\n",
      "0 700 91.94292974472046\n",
      "0 800 102.12234044075012\n",
      "0 900 90.93182480335236\n",
      "0 1000 98.44507944583893\n",
      "0 1100 89.18344008922577\n",
      "0 1200 86.41521036624908\n",
      "0 1300 105.0695321559906\n",
      "0 1400 79.62713313102722\n",
      "0 1500 88.61714017391205\n",
      "0 1600 88.7583315372467\n",
      "0 1700 82.42410004138947\n",
      "0 1800 87.35288631916046\n",
      "0 1900 95.7053200006485\n",
      "0 2000 89.13772678375244\n",
      "0 2100 80.19817388057709\n",
      "0 2200 90.68304550647736\n",
      "0 2300 88.64101684093475\n",
      "0 2400 81.06416523456573\n",
      "0 2500 84.81364691257477\n",
      "0 2600 80.93200087547302\n",
      "0 2700 89.21889507770538\n",
      "0 2800 84.6089243888855\n",
      "0 2900 90.50230264663696\n",
      "0 3000 79.34231495857239\n",
      "0 3100 80.7457947731018\n",
      "0 3200 85.82109928131104\n",
      "0 3300 93.03933846950531\n",
      "0 3400 79.94062691926956\n",
      "0 3500 81.09744966030121\n",
      "0 3600 71.09580951929092\n",
      "0 3700 78.79869568347931\n",
      "0 3800 68.5292586684227\n",
      "0 3900 88.59377717971802\n",
      "0 4000 99.1518343091011\n",
      "0 4100 74.49656140804291\n",
      "0 4200 74.44308936595917\n",
      "0 4300 83.56230282783508\n",
      "0 4400 84.32045191526413\n",
      "0 4500 79.8249100446701\n",
      "0 4600 74.90747702121735\n",
      "0 4700 82.44737827777863\n",
      "0 4800 90.45589923858643\n",
      "0 4900 69.734694480896\n",
      "0 5000 89.96608340740204\n",
      "0 5100 89.09781324863434\n",
      "0 5200 78.95796382427216\n",
      "0 5300 66.56317555904388\n",
      "0 5400 79.55528110265732\n",
      "0 5500 113.06396520137787\n",
      "0 5600 115.75235295295715\n",
      "0 5700 118.28262484073639\n",
      "0 5800 109.79388964176178\n",
      "0 5900 123.49558866024017\n",
      "0 6000 122.90584254264832\n",
      "0 6100 111.08416473865509\n",
      "0 6200 116.68315088748932\n",
      "0 6300 114.4786946773529\n",
      "0 6400 93.95606970787048\n",
      "0 6500 124.63318514823914\n",
      "0 6600 117.84476125240326\n",
      "0 6700 122.952401638031\n",
      "0 6800 106.11568939685822\n",
      "0 6900 110.46869349479675\n",
      "0 7000 111.62899100780487\n",
      "0 7100 110.97662019729614\n",
      "0 7200 105.04424047470093\n",
      "0 7300 113.91324126720428\n",
      "0 7400 115.88209021091461\n",
      "0 7500 98.29529070854187\n",
      "0 7600 105.97137105464935\n",
      "0 7700 110.84571290016174\n",
      "0 7800 103.721688747406\n",
      "0 7900 98.31990778446198\n",
      "0 8000 119.8665874004364\n",
      "0 8100 114.62586545944214\n",
      "0 8200 111.91850244998932\n",
      "0 8300 100.654909491539\n",
      "0 8400 109.7635155916214\n",
      "0 8500 104.5599513053894\n",
      "0 8600 103.86196780204773\n",
      "0 8700 111.24866902828217\n",
      "0 8800 105.07637882232666\n",
      "0 8900 108.953662276268\n",
      "0 9000 104.75923216342926\n",
      "0 9100 91.24821329116821\n",
      "0 9200 112.90602660179138\n",
      "0 9300 116.51076781749725\n",
      "0 9400 106.97306966781616\n",
      "0 9500 109.02660250663757\n",
      "0 9600 110.88614439964294\n",
      "0 9700 115.83899509906769\n",
      "0 9800 96.39089035987854\n",
      "0 9900 107.49617958068848\n",
      "0 10000 106.08157932758331\n",
      "0 10100 104.99745798110962\n",
      "0 10200 110.84607899188995\n",
      "0 10300 115.5061285495758\n",
      "0 10400 108.61524248123169\n",
      "0 10500 109.49849021434784\n",
      "0 10600 103.9452006816864\n",
      "0 10700 107.86690044403076\n",
      "0 10800 85.20244431495667\n",
      "0 10900 117.65711033344269\n",
      "0 11000 103.87161302566528\n",
      "0 11100 114.59197568893433\n",
      "0 11200 113.80819356441498\n",
      "0 11300 112.70549643039703\n",
      "0 11400 106.3153760433197\n",
      "0 11500 109.98615145683289\n",
      "0 11600 103.53290927410126\n",
      "0 11700 104.07376086711884\n",
      "0 11800 118.54704749584198\n",
      "0 11900 97.78353869915009\n",
      "0 12000 111.29751026630402\n",
      "0 12100 109.03786480426788\n",
      "0 12200 116.50756335258484\n",
      "0 12300 115.19922173023224\n",
      "0 12400 96.41362965106964\n",
      "0 12500 115.12837719917297\n",
      "0 12600 117.66775035858154\n",
      "0 12700 105.65628099441528\n",
      "0 12800 107.90819811820984\n",
      "0 12900 119.47854316234589\n",
      "0 13000 107.94612526893616\n",
      "0 13100 110.29982149600983\n",
      "0 13200 103.12208294868469\n",
      "0 13300 110.527623295784\n",
      "0 13400 101.31680738925934\n",
      "0 13500 111.40543961524963\n",
      "0 13600 104.0307766199112\n",
      "0 13700 93.57098472118378\n",
      "0 13800 99.9298187494278\n",
      "0 13900 106.59000945091248\n",
      "0 14000 91.90755653381348\n",
      "0 14100 99.53533947467804\n",
      "0 14200 96.59453594684601\n",
      "0 14300 106.56896376609802\n",
      "0 14400 111.08091056346893\n",
      "0 14500 105.37135779857635\n",
      "0 14600 113.51043248176575\n",
      "0 14700 105.73636150360107\n",
      "0 14800 110.26106369495392\n",
      "0 14900 107.2817188501358\n",
      "0 15000 115.03179609775543\n",
      "0 15100 106.92413449287415\n",
      "0 15200 91.37694847583771\n",
      "0 15300 109.40280342102051\n",
      "0 15400 107.5931681394577\n",
      "0 15500 100.06226456165314\n",
      "0 15600 94.92001438140869\n",
      "0 15700 113.58451581001282\n",
      "0 15800 98.6226053237915\n",
      "0 15900 102.13385331630707\n",
      "0 16000 114.7380645275116\n",
      "0 16100 116.76931488513947\n",
      "0 16200 108.61973857879639\n",
      "0 16300 111.10412037372589\n",
      "0 16400 99.18929159641266\n",
      "0 16500 101.19897329807281\n",
      "0 16600 100.96404016017914\n",
      "0 16700 102.19017231464386\n",
      "0 16800 116.02399826049805\n",
      "0 16900 102.5955194234848\n",
      "0 17000 110.16034007072449\n",
      "0 17100 112.65693545341492\n",
      "0 17200 101.03408205509186\n",
      "0 17300 108.86822652816772\n",
      "0 17400 111.94626331329346\n",
      "0 17500 104.16679906845093\n",
      "0 17600 94.74485158920288\n",
      "0 17700 111.87070870399475\n",
      "0 17800 104.53831040859222\n",
      "0 17900 105.07468748092651\n",
      "0 18000 109.69191122055054\n",
      "0 18100 102.9548864364624\n",
      "0 18200 114.5492205619812\n",
      "0 18300 108.28466725349426\n",
      "0 18400 99.0311564207077\n",
      "0 18500 99.68222868442535\n",
      "0 18600 111.43673992156982\n",
      "0 18700 113.0830682516098\n",
      "0 18800 99.17215383052826\n",
      "0 18900 101.8356968164444\n",
      "0 19000 98.69552481174469\n",
      "0 19100 90.39381515979767\n",
      "0 19200 60.16045105457306\n",
      "0 19300 67.11737418174744\n",
      "0 19400 94.4134327173233\n",
      "0 19500 79.0427862405777\n",
      "0 19600 74.60669338703156\n",
      "0 19700 81.0457272529602\n",
      "0 19800 79.46772706508636\n",
      "0 19900 89.16177594661713\n",
      "0 20000 79.60915684700012\n",
      "0 20100 93.49211132526398\n",
      "0 20200 78.61340945959091\n",
      "0 20300 76.09264653921127\n",
      "0 20400 78.8262255191803\n",
      "0 20500 66.88310921192169\n",
      "0 20600 72.07528412342072\n",
      "0 20700 84.090780377388\n",
      "0 20800 87.24698317050934\n",
      "0 20900 73.02068150043488\n",
      "0 21000 72.38255321979523\n",
      "0 21100 77.53114128112793\n",
      "0 21200 94.33501958847046\n",
      "0 21300 78.97756445407867\n",
      "0 21400 73.83167612552643\n",
      "0 21500 54.81125444173813\n",
      "0 21600 65.3445440530777\n",
      "0 21700 77.61855816841125\n",
      "0 21800 84.00173151493073\n",
      "0 21900 65.45368564128876\n",
      "0 22000 89.77785968780518\n",
      "0 22100 67.2650375366211\n",
      "0 22200 84.56886672973633\n",
      "0 22300 61.90488278865814\n",
      "0 22400 76.80941486358643\n",
      "0 22500 98.38449490070343\n",
      "0 22600 101.08498501777649\n",
      "0 22700 105.32186949253082\n",
      "0 22800 105.61246681213379\n",
      "0 22900 114.6858378648758\n",
      "0 23000 106.05131363868713\n",
      "0 23100 85.01739132404327\n",
      "0 23200 70.82328277826309\n",
      "0 23300 74.81537944078445\n",
      "0 23400 103.96872806549072\n",
      "0 23500 71.11010217666626\n",
      "0 23600 83.61746722459793\n",
      "0 23700 74.48578929901123\n",
      "0 23800 72.15215134620667\n",
      "0 23900 70.44947731494904\n",
      "0 24000 84.1440589427948\n",
      "0 24100 71.30966508388519\n",
      "0 24200 83.79458105564117\n",
      "0 24300 87.10808324813843\n",
      "0 24400 74.69928777217865\n",
      "0 24500 92.90439581871033\n",
      "0 24600 66.44449877738953\n",
      "0 24700 66.62411308288574\n",
      "0 24800 78.90529882907867\n",
      "0 24900 66.78256368637085\n",
      "0 25000 75.1663601398468\n",
      "0 25100 86.13982957601547\n",
      "0 25200 84.07286274433136\n",
      "0 25300 73.27712315320969\n",
      "0 25400 59.40912663936615\n",
      "0 25500 77.77430659532547\n",
      "0 25600 74.52569305896759\n",
      "0 25700 76.60356283187866\n",
      "0 25800 69.10837531089783\n",
      "0 25900 68.74227297306061\n",
      "0 26000 64.9165631532669\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for ep in tqdm(range(10)):\n",
    "    i, lossK=0 ,0.0\n",
    "    for xs, ys in dataloader:\n",
    "        xsl, xmsk = [], []\n",
    "        for k in range(len(xs)):\n",
    "            tid = xs[k]\n",
    "            xsl.append(torch.LongTensor(tid))\n",
    "            xmsk.append(torch.LongTensor([l]*len(tid))\n",
    "        \n",
    "        xsl = pad_sequence(xsl, batch_first = True).to(device)\n",
    "        xmsk = pad_sequence(xmsk, batch_first = True).to(device)\n",
    "        outputs = net(xsl, xmsk) \n",
    "                        \n",
    "        dummy_y  =[]\n",
    "        added_flg = 0\n",
    "\n",
    "        # 同率１位は、先のほうにする。\n",
    "                        \n",
    "        for tmp_y in ys:\n",
    "            for index, yy in enumerate(tmp_y[1:-1].split(\",\")):\n",
    "                if \"1\" in yy and added_flg == 0:\n",
    "                    dummy_y.append(index)\n",
    "                    added_flg = 1\n",
    "\n",
    "        ys = torch.LongTensor(dummy_y).to(device)\n",
    "    #         print(\"out:\", out.size(), \"y:\", y.size())\n",
    "\n",
    "        loss = criterion(outputs, ys)\n",
    "        lossK += loss.item()\n",
    "\n",
    "            if (i % 500 == 0 ):\n",
    "                print(ep, i, lossK)\n",
    "                lossK = 0.0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    outfile = \"doccls - \"+ str(ep) + \".model\"\n",
    "    torch.save(net.state_dict().outfile)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_num, ok =0, 0\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(x_test)):\n",
    "        x = torch.LongTensor(x_test[i].unsqueeze(0).to(device))\n",
    "        ans =  net(x)\n",
    "        ans1 = torch.argmax(ans,dim=1).item()\n",
    "        if (ans1 == y_test[i]):\n",
    "            ok += 1\n",
    "        real_data_num += 1\n",
    "print(ok, read_data_num, ok,/real_data_num)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
