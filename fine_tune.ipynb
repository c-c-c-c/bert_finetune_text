{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from icecream import ic\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from transformers import BertModel\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"9\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "\n",
    "with open(\"../BERT-base_mecab-ipadic-bpe-32k/vocab.txt\",  \"r\", encoding=\"utf-8\" ) as f:\n",
    "    vocab = f.read()\n",
    "    for id, word in enumerate(vocab.split('\\n')):\n",
    "        dic[word] = id\n",
    "        \n",
    "text = \"[CLS] 私 は 犬 が 好き 。 [SEP]\"\n",
    "\n",
    "x = [dic[w] for w in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(x).unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = bert(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2636e-01, -1.2734e-01,  4.1125e-01, -3.7946e-02,  3.5671e-01,\n",
       "         5.9472e-01, -1.2080e-02, -2.0193e-01,  6.1377e-01,  2.1312e-01,\n",
       "        -7.4529e-02,  2.0608e-02, -4.5949e-01,  2.5509e-01, -2.4717e-01,\n",
       "        -9.4191e-02,  1.1410e-01, -2.2248e-01,  3.5165e-01,  4.6572e-01,\n",
       "        -3.8768e-01, -8.5532e-02,  2.5526e-01,  2.6166e-01, -3.1824e-01,\n",
       "         8.1794e-02, -2.4993e-01,  2.9269e-01,  7.9955e-01,  3.5923e-01,\n",
       "        -1.2338e-01,  6.5812e-03,  3.8730e-01,  2.3091e-01,  1.4636e-01,\n",
       "         4.6668e-01,  2.6290e-01,  1.6372e-01,  6.9316e-02,  1.4958e-01,\n",
       "        -5.9775e-01,  2.1966e-01, -1.5152e-01, -7.7528e-03,  2.8760e-02,\n",
       "         8.2232e-01, -2.1874e-01,  4.2410e-02,  8.8731e-01,  9.9789e-02,\n",
       "        -6.2738e-01, -4.2279e-01,  9.3123e-03, -3.0431e-01, -2.4775e-01,\n",
       "        -9.0133e-02,  1.4442e+00,  2.2802e-01,  4.4458e-01, -3.1874e-01,\n",
       "        -6.9717e-01,  6.2764e-01, -3.7871e-02, -6.9396e-02,  1.3187e-01,\n",
       "        -1.4630e-01, -9.5384e-02, -4.0134e-02, -1.1419e+00,  5.0267e-01,\n",
       "        -5.0180e-01,  6.6902e-01, -8.6004e-01, -2.8318e-02,  2.4716e-01,\n",
       "         5.5095e-01, -2.2537e-01,  1.9594e-01,  2.7266e-01, -3.5039e-01,\n",
       "        -2.2121e-01, -4.8057e-02,  2.1614e-01,  3.7493e-01,  1.5255e-01,\n",
       "        -2.2028e-02, -7.3651e-01,  5.6596e-01, -1.2990e-01, -2.1525e-01,\n",
       "         4.9725e-01,  3.2755e-01,  1.4070e-01, -1.4203e-01, -3.0324e-01,\n",
       "         4.9558e-01, -2.0771e-01, -4.6211e-01,  1.1700e-01,  4.6133e-03,\n",
       "        -7.4607e-01, -7.8644e-01,  4.3173e-01, -7.4613e-01,  5.7458e-02,\n",
       "        -6.4743e-03, -5.6369e-01,  3.6449e-01,  2.7439e-01,  4.5760e-01,\n",
       "         1.3098e-01,  7.3430e-01,  3.4693e-01, -9.2957e-02,  2.2157e-01,\n",
       "        -5.9410e-01, -3.3102e-01,  4.8622e-02,  3.9111e-01,  2.0070e-01,\n",
       "         1.2561e-01,  2.8281e-01,  5.6432e-01,  2.8840e-01, -1.3205e-01,\n",
       "        -1.6940e-01,  1.1061e+00, -4.8166e-01, -7.7946e-02, -4.8893e-01,\n",
       "        -4.7354e-02, -7.6424e-01, -9.1521e-01,  4.7544e-01, -3.2645e-01,\n",
       "         2.8502e-01, -3.3783e-02,  7.2673e-01, -3.5925e-01, -2.1302e-01,\n",
       "         3.1164e-01,  2.7859e-01,  9.4417e-01,  4.2333e-01,  8.9327e-01,\n",
       "        -2.9452e-01,  6.2696e-01, -6.7386e-02,  1.7236e-01, -4.0853e-01,\n",
       "         4.3754e-01,  2.2073e-01, -7.0428e-01, -1.1578e-01, -2.6477e-01,\n",
       "        -4.3494e-01, -6.9601e-01, -5.0655e-01,  5.9983e-01,  1.0477e+00,\n",
       "        -7.3032e-01,  3.4891e-01, -1.9410e-01,  5.7067e-02,  4.9292e-01,\n",
       "        -3.2191e-01, -3.6206e-01,  6.9024e-01, -1.8361e-01,  8.5708e-02,\n",
       "         9.0006e-02,  4.2827e-01, -1.7562e-01, -1.1233e-02, -4.9506e-01,\n",
       "         3.5904e-01,  2.4320e-01,  1.8439e-01, -1.8764e-01, -1.9291e-01,\n",
       "        -4.6769e-01,  3.3824e-02,  1.7553e-01, -5.8764e-01, -2.7029e-01,\n",
       "         4.9463e-01, -7.9573e-01,  4.0490e-01, -1.6254e-01,  2.5074e-01,\n",
       "         4.5026e-01,  5.9887e-01,  4.5802e-01, -6.8991e-01, -1.1518e-01,\n",
       "        -7.1103e-02,  4.3074e-01,  1.2597e-01, -1.7785e-02,  1.3623e-01,\n",
       "         1.4732e-01, -1.4807e-02,  1.8128e-01,  1.3673e-01,  4.8054e-02,\n",
       "         9.2967e-01,  5.2012e-02, -1.2880e-01, -5.5237e-02,  2.6225e-01,\n",
       "         5.6227e-02, -7.2467e-03,  3.8972e-02, -8.8316e-02,  8.3572e-02,\n",
       "        -4.1377e-01, -5.0239e-03,  2.6995e-01, -8.7080e-02,  2.5820e-01,\n",
       "         8.8450e-02,  4.4651e-01,  7.7217e-01,  5.7551e-03,  4.0472e-01,\n",
       "         5.5931e-02,  8.5114e-01, -5.7391e-01,  1.6231e-01, -4.9489e-02,\n",
       "        -2.2377e-01, -4.7706e-01,  5.2503e-01, -1.6769e-01, -9.1922e-02,\n",
       "         3.7336e-01, -3.5309e-01,  7.0598e-01,  3.9674e-01, -5.3772e-02,\n",
       "         6.9892e-01, -1.5170e-01, -1.9310e-01,  3.7981e-01, -7.6653e-01,\n",
       "        -3.5357e-01, -1.2882e-02, -3.1287e-02, -5.5400e-01,  3.6271e-01,\n",
       "         1.2920e-01,  2.1026e-01, -3.9403e-01, -4.6997e-02, -4.6301e-01,\n",
       "        -5.4901e-01,  3.6518e-01, -1.3955e+00,  5.5823e-02,  6.5063e-01,\n",
       "        -3.1004e-03,  3.7068e-02, -3.9735e-01,  7.0079e-02, -7.7613e-01,\n",
       "        -1.8507e-01, -2.9915e-01,  6.3105e-01, -2.1384e-01,  4.7937e-01,\n",
       "        -3.0145e-02, -1.0822e-01,  3.3522e-01,  5.3279e-01, -3.9141e-01,\n",
       "        -2.5561e-01, -6.2588e-01, -3.5809e-01,  6.3246e-01,  1.7020e-01,\n",
       "        -5.3728e-03, -1.5626e-01, -1.5021e+00, -4.9895e-01, -4.2466e-02,\n",
       "         8.3843e-01,  4.7990e-02, -5.1288e-02, -2.7274e-01, -6.2329e-01,\n",
       "        -8.6088e-02,  4.1608e-01,  1.1139e-01,  3.4601e-01,  9.7202e-01,\n",
       "         2.0434e-01, -2.3330e-01,  8.2589e-03, -1.0363e-01,  8.6864e-02,\n",
       "         1.7144e-01, -4.5553e-03,  2.9243e-02,  1.4029e-01,  1.9651e-01,\n",
       "         1.3921e-02, -8.1708e-01,  4.2241e-01,  7.6434e-01,  8.5447e-02,\n",
       "        -2.4554e-01,  6.1175e-01,  3.1224e-01,  7.4443e-01,  2.6618e-01,\n",
       "        -3.2915e-01,  1.9511e-01,  2.8974e-01,  4.1188e-01,  1.0091e-01,\n",
       "        -5.6285e-01, -3.0537e-01, -4.6778e-01,  2.2863e-01,  9.7901e-04,\n",
       "        -5.3482e-01,  1.9482e-01, -1.4910e-02, -2.8754e-01,  1.5458e-01,\n",
       "        -1.9697e-01,  2.3194e-01, -4.5634e-01, -9.4692e-02, -4.7934e-01,\n",
       "        -4.4342e-01,  1.3820e-01,  2.7414e-01, -1.8712e-02, -1.9631e-01,\n",
       "         1.0009e-01,  7.8175e-01, -3.9911e-02,  9.0097e-01, -4.5911e-01,\n",
       "        -1.5239e-01, -3.2153e-02,  1.9477e-01, -2.3704e-01,  1.0202e-03,\n",
       "         6.4125e-01,  2.5652e-01,  1.1754e-01, -6.6058e-01, -1.4489e-01,\n",
       "         5.1765e-02,  5.1428e-01, -4.5977e-01,  1.3868e-01,  1.0421e-01,\n",
       "        -2.9658e-02,  2.8779e-01,  6.9075e-01,  5.4622e-01, -6.3122e-01,\n",
       "        -7.2606e-02, -7.9440e-01, -2.0620e-01, -4.2225e-01, -1.6070e-01,\n",
       "        -8.6649e-02,  1.4101e-01, -7.5491e-01,  1.0600e-01,  2.4214e-01,\n",
       "        -5.3326e-01, -6.1987e-01, -3.4620e-01,  1.5708e-01, -1.4969e-01,\n",
       "         3.6526e-01, -1.8333e-01, -5.9828e-01, -3.4726e-01, -2.9197e-01,\n",
       "        -3.8246e-01,  2.4109e-01,  8.2283e-02,  1.8602e-01,  3.7789e-01,\n",
       "        -6.1797e-02,  3.6415e-02, -4.1763e-01, -1.1590e-01,  2.4209e-01,\n",
       "         3.5159e-01, -2.3424e-01, -2.0255e-01,  2.8956e-01,  7.0934e-03,\n",
       "        -4.4297e-01, -4.4249e-02, -3.1908e-01,  3.1051e-02,  4.8135e-01,\n",
       "         2.4680e-01,  2.7877e-01, -3.7734e-01, -1.0593e-01,  1.6187e-01,\n",
       "         5.0757e-01, -1.0019e+00, -8.7185e-02,  2.9606e-01,  1.3530e-02,\n",
       "         8.6630e-02,  3.3357e-01, -7.5095e-01, -2.1433e-02, -5.4963e-01,\n",
       "         3.1206e-01, -5.5403e-02, -1.0946e+00,  1.3473e-01,  3.9708e-01,\n",
       "         2.7739e-01, -4.6436e-01, -5.4644e-02, -3.9295e-01, -1.2051e-01,\n",
       "        -3.2665e-01, -1.0662e-03,  5.2600e-02,  3.5859e-01, -2.0447e-01,\n",
       "         1.0261e+00,  6.0770e-01, -6.9690e-01, -4.3956e-01,  8.3881e-01,\n",
       "         7.7650e-01,  1.4149e-01, -1.2465e-01,  4.8639e-01, -3.6845e-01,\n",
       "        -3.9505e-01, -2.2520e-01,  7.1529e-01, -1.2594e-01, -3.9724e-01,\n",
       "        -2.9168e-01, -6.2677e-01, -3.3448e-01,  5.9854e-01,  2.0486e-01,\n",
       "         3.9802e-01,  1.2763e-01, -5.7305e-01,  2.1901e-01,  1.2301e-01,\n",
       "        -4.7575e-01,  4.0336e-01,  2.2059e-01, -3.4848e-02, -3.1772e-01,\n",
       "         7.4034e-02, -9.9276e-02, -6.3303e-02,  6.7730e-01, -7.9260e-01,\n",
       "        -4.5202e-02,  5.2365e-01, -2.7718e-02,  5.9223e-03, -9.1440e-02,\n",
       "         6.5027e-01,  5.0533e-01,  3.6670e-02,  6.4551e-01,  1.9206e-03,\n",
       "        -8.6307e-02, -7.2769e-02, -2.6181e-01,  2.8473e-01, -8.0327e-01,\n",
       "         1.6735e-01,  7.1643e-01,  3.0394e-01, -4.1841e-01,  4.9319e-01,\n",
       "         4.9865e-01,  4.2977e-01,  2.0655e-01, -6.0212e-01, -1.8473e-01,\n",
       "         1.1200e-02,  1.9169e-01, -3.7922e-01,  5.0830e-02,  1.4850e-01,\n",
       "         5.5978e-01,  3.6470e-01,  7.7679e-02, -3.8389e-01, -4.8850e-01,\n",
       "         2.3830e-01,  3.9645e-01, -8.9931e-01, -1.8844e-01, -2.7444e-01,\n",
       "         1.8547e-01,  2.4568e-01, -2.1540e-01, -2.8980e-02,  5.0126e-01,\n",
       "        -5.6360e-01, -2.7866e-01, -1.9295e-01,  9.1583e-01, -3.0396e-01,\n",
       "        -1.7067e-01, -1.2645e-01, -4.1039e-01, -9.2601e-02, -2.6981e-01,\n",
       "         1.2651e-01,  5.6678e-01,  1.9600e-01, -2.8665e-01,  4.0650e-01,\n",
       "         1.2173e-01, -1.7194e-01,  8.4419e-01,  3.3347e-01,  4.3319e-02,\n",
       "         1.3786e-02, -1.6547e-01, -5.3772e-01,  2.0879e-01,  2.2129e-01,\n",
       "         6.6415e-02, -1.2108e-01,  6.2374e-01, -5.7487e-01,  9.1839e-01,\n",
       "        -6.1932e-01, -8.0079e-02, -2.3511e-01,  3.1379e-01,  4.0686e-01,\n",
       "         2.8223e-01, -5.3857e-01, -2.6997e-01, -7.6706e-02, -2.8245e-01,\n",
       "        -2.6830e-01, -4.4252e-01,  2.3550e-01, -8.6242e-01,  2.1785e-02,\n",
       "        -1.3134e-01,  9.0185e-02, -1.0116e-01,  2.9397e-01, -6.3964e-03,\n",
       "        -5.5898e-01,  1.2330e-01, -6.4213e-01,  2.6501e-01, -1.6842e-02,\n",
       "        -4.7033e-01,  1.7309e-01, -5.6419e-02,  5.7463e-01, -7.6251e-01,\n",
       "         1.6844e-01, -1.1225e-01,  3.3626e-01,  4.9026e-02, -2.5254e-01,\n",
       "         1.6437e-01,  5.5116e-01, -5.1896e-01,  5.4747e-02, -5.2932e-01,\n",
       "         3.6159e-01,  7.1701e-01, -1.7432e-01, -4.3881e-01, -3.2366e-01,\n",
       "        -5.0767e-01, -2.0115e-01, -2.2987e-01, -4.9926e-01,  5.8573e-01,\n",
       "         3.9168e-01,  2.9184e-01, -7.7926e-01,  2.4396e-01, -2.0216e-01,\n",
       "        -4.8349e-01,  1.2666e-01,  5.7137e-01,  3.6593e-01,  2.5444e-01,\n",
       "        -3.8959e-01,  1.4999e-01, -7.0352e-01,  2.5381e-01,  1.3579e-01,\n",
       "         4.2275e-01, -6.3476e-01, -1.6673e-01, -7.6727e-02,  5.0017e-01,\n",
       "        -1.3614e+00,  1.7419e-01, -1.1971e-01,  3.5219e-01,  2.5904e-01,\n",
       "         9.0094e-02,  8.5215e-01, -2.4464e-01,  3.9043e-01,  9.1599e-01,\n",
       "         2.2390e-01,  2.3598e-02, -9.1799e-01, -3.8023e-02, -1.1525e-01,\n",
       "         9.5774e-02, -4.0080e-02,  5.8575e-01, -5.8251e-01,  3.8501e-03,\n",
       "        -7.6207e-01, -7.1315e-02, -2.6048e-01,  3.2383e-01, -7.0393e-01,\n",
       "         5.1572e-01, -1.7971e-01, -1.0781e-01, -2.4707e-01, -4.3959e-02,\n",
       "        -5.0989e-02,  5.9210e-01, -1.5463e-02, -1.4231e-01, -2.3543e-01,\n",
       "         2.3660e-01, -3.6423e-01, -6.1305e-02, -4.9595e-01,  1.1677e-01,\n",
       "        -6.2476e-03, -4.6197e-02,  8.3986e-02,  7.9944e-02,  2.1710e-01,\n",
       "         6.3772e-01,  1.9252e-01,  1.1059e-01,  1.2271e-01, -2.7933e-01,\n",
       "         2.7812e-01, -3.0458e-01, -3.6236e-01, -9.9733e+00,  5.3445e-01,\n",
       "        -6.1084e-01,  3.5478e-01, -4.4430e-01,  2.0473e-01,  4.9334e-01,\n",
       "         3.0226e-01,  4.9448e-01,  1.9301e-01,  1.4200e-01, -6.0790e-02,\n",
       "        -6.7130e-02, -2.9199e-01, -5.6820e-01,  8.4747e-01, -4.0862e-01,\n",
       "        -2.3701e-01,  8.0204e-01, -4.0005e-01, -8.3642e-01, -3.4560e-01,\n",
       "        -3.7893e-01,  3.7334e-01,  8.7733e-02,  8.1779e-02, -9.3863e-01,\n",
       "        -8.8667e-02, -2.5217e-01,  1.8868e-01, -3.3601e-01,  2.4337e-01,\n",
       "        -9.0584e-01, -2.7559e-01, -2.9569e-01, -1.2442e-01,  2.8073e-01,\n",
       "         4.0143e-01,  2.0874e-01,  4.8844e-01, -3.7374e-01, -1.7950e-01,\n",
       "        -6.7642e-02, -1.0630e+00,  6.5236e-01, -2.8368e-01,  4.4323e-01,\n",
       "         6.4191e-02,  2.3430e-01, -3.6649e-02, -1.5684e-01, -2.6421e-01,\n",
       "        -3.6368e-01, -6.9880e-01, -1.6153e-01, -1.8823e-01,  4.6617e-02,\n",
       "         9.3144e-02,  1.0430e-02,  6.0366e-01,  2.8327e-01,  1.1565e-01,\n",
       "        -8.7768e-02,  4.7500e-01, -2.3949e-01,  5.8169e-01,  2.5403e-01,\n",
       "         4.1323e-01, -7.0600e-01,  4.1934e-01,  1.0501e-01,  9.9605e-02,\n",
       "         7.5673e-02,  5.1302e-01, -2.6561e-01, -5.4856e-01, -7.2084e-01,\n",
       "        -3.3494e-01,  8.0041e-01,  9.5123e-02, -4.3697e-01, -2.6048e-01,\n",
       "        -7.0522e-01,  2.9933e-01,  2.2629e-01, -9.8538e-02,  3.0781e-01,\n",
       "        -2.2554e-01,  5.4424e-01, -3.6351e-01,  1.6985e-01,  4.8340e-01,\n",
       "        -3.1554e-01,  5.9462e-02, -5.6606e-01,  1.9571e-01,  3.2333e-01,\n",
       "         3.6122e-01, -2.9694e-01, -3.1038e-01], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer\n",
    "\n",
    "tknz = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['私', 'は', '犬', 'が', '好き']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tknz.tokenize(\"私は犬が好き\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = tknz.encode(\"私は[MASK]が好き\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertForMaskedLM\n",
    "\n",
    "# model = BertForMaskedLM.from_pretrained('cl-tohoku/bert-base-japanese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = model(torch.LongTensor(ids).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mskpos = 3\n",
    "# b=torch.topk(a[0][0][mskpos], k=5)\n",
    "# tknz.convert_ids_to_tokens(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = [],[]\n",
    "y_train, y_test = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train_twitterJSA_data.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"../data/test_twitterJSA_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = train_df[\"label\"].tolist()\n",
    "# y_test = test_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201027b83e0f45a981156ee3595c2ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1841495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in tqdm(range(len(train_df))):\n",
    "#     print(ind)\n",
    "    \n",
    "    if type(train_df[\"text\"].iloc[ind]  ) != str:\n",
    "        continue\n",
    "    tid = tknz.encode(train_df[\"text\"].iloc[ind]) \n",
    "    \n",
    "    if (len(tid)>512):\n",
    "        tid = tid[:512]\n",
    "    x_train.append(tid)\n",
    "    y_train.append(train_df[\"label\"].iloc[ind])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(x_train[1])\n",
    "\n",
    "# net(torch.LongTensor(x_train[1]).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    if (len(x_train[i])) < 2:\n",
    "        print(x_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8f17d4785244dd8bb913197a31b12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=107004.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in tqdm(range(len(test_df))):\n",
    "    \n",
    "    if type(test_df[\"text\"].iloc[ind] ) != str:\n",
    "        continue\n",
    "    \n",
    "    tid = tknz.encode(test_df[\"text\"].iloc[ind]) \n",
    "    if (len(tid)>512):\n",
    "        tid = tid[:512]\n",
    "    x_test.append(tid)\n",
    "    y_test.append(test_df[\"label\"].iloc[ind])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocCls(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(DocCls, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.cls = nn.Linear(768, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bout = self.bert(x)\n",
    "        bs = len(bout[0])\n",
    "        h0 = [bout[0][i][0] for i in range(bs)]\n",
    "        h0 = torch.stack(h0, dim=0)\n",
    "        return self.cls(h0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "net = DocCls(bert)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc158123c43245b49c2a599f1d5af118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.273510456085205\n",
      "0 2000 2098.084459245205\n",
      "0 4000 1830.7071210741997\n",
      "0 6000 1706.9611879587173\n",
      "0 8000 1647.992381453514\n",
      "0 10000 1618.5863126516342\n",
      "0 12000 1540.898620545864\n",
      "0 14000 1501.5223188996315\n",
      "0 16000 1420.421553492546\n",
      "0 18000 1472.0156088471413\n",
      "0 20000 1402.6514811515808\n",
      "0 22000 1439.4924801588058\n",
      "0 24000 1360.3003531694412\n",
      "0 26000 1342.4875227808952\n",
      "0 28000 1369.2085596323013\n",
      "0 30000 1337.4415910243988\n",
      "0 32000 1331.3727125525475\n",
      "0 34000 1384.6455251574516\n",
      "0 36000 1263.418677330017\n",
      "0 38000 1366.0616002082825\n",
      "0 40000 1337.9645774364471\n",
      "0 42000 1222.2548843622208\n",
      "0 44000 1288.8126438856125\n",
      "0 46000 1301.2395622730255\n",
      "1 2000 1256.0370894670486\n",
      "1 4000 1268.7430146932602\n",
      "1 6000 1297.8115581274033\n",
      "1 8000 1255.544875562191\n",
      "1 10000 1284.3062624931335\n",
      "1 12000 1207.629076719284\n",
      "1 14000 1207.10584461689\n",
      "1 16000 1169.90454351902\n",
      "1 18000 1221.1940683722496\n",
      "1 20000 1158.1328610181808\n",
      "1 22000 1187.691885650158\n",
      "1 24000 1116.101574063301\n",
      "1 26000 1118.096886396408\n",
      "1 28000 1130.0950382351875\n",
      "1 30000 1137.1910852789879\n",
      "1 32000 1122.0209838747978\n",
      "1 34000 1179.925330400467\n",
      "1 36000 1071.5772451758385\n",
      "1 38000 1168.1947204470634\n",
      "1 40000 1163.2404401302338\n",
      "1 42000 1066.269404232502\n",
      "1 44000 1100.991992354393\n",
      "1 46000 1145.7584909796715\n",
      "1 50000 1132.1045810580254\n",
      "2 0 2.095651865005493\n",
      "2 2000 1101.3071534633636\n",
      "2 4000 1098.8286238312721\n",
      "2 6000 1144.2533485889435\n",
      "2 8000 1112.500470995903\n",
      "2 10000 1134.0981526970863\n",
      "2 12000 1067.1886817216873\n",
      "2 14000 1064.4612580537796\n",
      "2 16000 1008.2809104919434\n",
      "2 18000 1058.3767575621605\n",
      "2 20000 1028.1482034921646\n",
      "2 22000 1071.7740560173988\n",
      "2 24000 1000.030005812645\n",
      "2 26000 982.2367136478424\n",
      "2 28000 1009.0422105789185\n",
      "2 30000 975.767182290554\n",
      "2 32000 971.1736847758293\n",
      "2 34000 1043.5797923207283\n",
      "2 36000 942.7545213103294\n",
      "2 38000 1001.7892925143242\n",
      "2 40000 1029.508385181427\n",
      "2 42000 957.7993499040604\n",
      "2 44000 978.9075483083725\n",
      "2 46000 1034.2860483527184\n",
      "2 50000 1032.6691323518753\n",
      "3 0 1.8802649974822998\n",
      "3 2000 969.9977616071701\n",
      "3 4000 1006.5502016544342\n",
      "3 6000 1032.8920094966888\n",
      "3 8000 1006.1922549009323\n",
      "3 10000 1020.6357550621033\n",
      "3 12000 942.7367930412292\n",
      "3 14000 974.6193908452988\n",
      "3 16000 887.7298929691315\n",
      "3 18000 942.0912135243416\n",
      "3 20000 941.3058725595474\n",
      "3 22000 968.3098002672195\n",
      "3 24000 935.8249952793121\n",
      "3 26000 944.3861302137375\n",
      "3 28000 891.6778934001923\n",
      "3 30000 846.4089184999466\n",
      "3 32000 881.1520155668259\n",
      "3 34000 925.3560347557068\n",
      "3 36000 849.1893342733383\n",
      "3 38000 908.1993693709373\n",
      "3 40000 943.292059481144\n",
      "3 42000 857.489369392395\n",
      "3 44000 877.1729345321655\n",
      "3 46000 899.7984716892242\n",
      "3 48000 921.2642041444778\n",
      "3 50000 947.597703397274\n",
      "4 0 1.8191096782684326\n",
      "4 2000 889.3913935422897\n",
      "4 4000 921.4036197662354\n",
      "4 6000 955.948123216629\n",
      "4 8000 933.9360272884369\n",
      "4 10000 956.8793939352036\n",
      "4 12000 860.6642348766327\n",
      "4 14000 868.4741624593735\n",
      "4 16000 809.6345671415329\n",
      "4 18000 840.1198521852493\n",
      "4 20000 840.569135248661\n",
      "4 22000 853.192886531353\n",
      "4 24000 855.2607234716415\n",
      "4 26000 835.3288444280624\n",
      "4 28000 825.40367436409\n",
      "4 30000 776.9586386680603\n",
      "4 32000 829.5046664476395\n",
      "4 34000 796.1962380409241\n",
      "4 36000 796.568465590477\n",
      "4 38000 807.3887305855751\n",
      "4 40000 834.9980922937393\n",
      "4 42000 791.1369705796242\n",
      "4 44000 793.4431937932968\n",
      "4 46000 806.1547047495842\n",
      "4 48000 849.515992641449\n",
      "4 50000 814.8745372891426\n",
      "5 0 1.1625081300735474\n",
      "5 2000 801.193745970726\n",
      "5 4000 846.7259638309479\n",
      "5 6000 871.8892598748207\n",
      "5 8000 829.1756318807602\n",
      "5 10000 835.2821103334427\n",
      "5 12000 793.3991627693176\n",
      "5 14000 789.0566486120224\n",
      "5 16000 739.3374274969101\n",
      "5 18000 761.4210522770882\n",
      "5 20000 725.8166781067848\n",
      "5 22000 767.4009491205215\n",
      "5 24000 714.718508720398\n",
      "5 26000 755.5713613033295\n",
      "5 28000 732.8677513599396\n",
      "5 30000 646.770672917366\n",
      "5 32000 745.736779332161\n",
      "5 34000 779.3311764001846\n",
      "5 36000 707.68956387043\n",
      "5 38000 742.9874151945114\n",
      "5 40000 763.3829418420792\n",
      "5 42000 714.9794663190842\n",
      "5 44000 745.4890358448029\n",
      "5 46000 778.514124751091\n",
      "5 48000 790.3201676607132\n",
      "5 50000 787.8269349336624\n",
      "6 0 0.9588217735290527\n",
      "6 2000 741.1255884170532\n",
      "6 4000 746.8598718643188\n",
      "6 6000 777.6346936225891\n",
      "6 8000 731.934264421463\n",
      "6 10000 846.5600687265396\n",
      "6 12000 709.8847545385361\n",
      "6 14000 724.3183866739273\n",
      "6 16000 691.0917812585831\n",
      "6 18000 691.2353150844574\n",
      "6 20000 656.5418432950974\n",
      "6 22000 667.8214591741562\n",
      "6 24000 713.5050241947174\n",
      "6 26000 697.1067998409271\n",
      "6 28000 659.4658542871475\n",
      "6 30000 624.6618680357933\n",
      "6 32000 656.3169991970062\n",
      "6 34000 676.9436829090118\n",
      "6 36000 623.022646188736\n",
      "6 38000 675.3636773824692\n",
      "6 40000 674.0623191595078\n",
      "6 42000 630.5101212263107\n",
      "6 44000 653.5205199718475\n",
      "6 46000 677.3026529550552\n",
      "6 48000 703.6812024116516\n",
      "6 50000 687.3615432977676\n",
      "7 0 1.2821295261383057\n",
      "7 2000 628.8392014503479\n",
      "7 4000 669.1300560235977\n",
      "7 6000 748.2391000986099\n",
      "7 8000 649.573765873909\n",
      "7 10000 749.369863152504\n",
      "7 12000 614.4801660776138\n",
      "7 14000 681.2006652355194\n",
      "7 16000 592.811203122139\n",
      "7 18000 575.089506149292\n",
      "7 20000 625.1900407075882\n",
      "7 22000 641.7940047979355\n",
      "7 24000 654.6771469116211\n",
      "7 26000 642.490824341774\n",
      "7 28000 606.8123366832733\n",
      "7 30000 563.3118089437485\n",
      "7 32000 634.8853079080582\n",
      "7 34000 638.1064608097076\n",
      "7 36000 634.9499789476395\n",
      "7 38000 599.1273934841156\n",
      "7 40000 625.3663059473038\n",
      "7 42000 615.1197334527969\n",
      "7 44000 611.3594156503677\n",
      "7 46000 627.7503312826157\n",
      "7 48000 599.1410038471222\n",
      "7 50000 670.5667150020599\n",
      "8 0 0.48117828369140625\n",
      "8 2000 605.6364327669144\n",
      "8 4000 630.0217813253403\n",
      "8 6000 677.33307492733\n",
      "8 8000 603.4630640745163\n",
      "8 10000 645.4345947504044\n",
      "8 12000 625.737988948822\n",
      "8 14000 588.5711289644241\n",
      "8 16000 576.3261920213699\n",
      "8 18000 538.4088162779808\n",
      "8 20000 570.1520602703094\n",
      "8 22000 581.2773710489273\n",
      "8 24000 593.1696841716766\n",
      "8 26000 568.074432849884\n",
      "8 28000 536.3454486131668\n",
      "8 30000 518.281081199646\n",
      "8 32000 536.2648035287857\n",
      "8 34000 536.2062296867371\n",
      "8 36000 524.3582502603531\n",
      "8 38000 544.6144746541977\n",
      "8 40000 543.9102016687393\n",
      "8 42000 566.399825334549\n",
      "8 44000 528.274949669838\n",
      "8 46000 560.781033039093\n",
      "8 48000 577.1922687292099\n",
      "8 50000 549.3018608093262\n",
      "9 0 0.644218921661377\n",
      "9 2000 560.6179364919662\n",
      "9 4000 559.8381496667862\n",
      "9 6000 616.12109375\n",
      "9 8000 549.0405684709549\n",
      "9 10000 638.6558671593666\n",
      "9 12000 582.5296851396561\n",
      "9 14000 540.4281449317932\n",
      "9 16000 465.07318449020386\n",
      "9 18000 532.1037117242813\n",
      "9 20000 497.9392417669296\n",
      "9 22000 464.2891001701355\n",
      "9 24000 516.1097530126572\n",
      "9 26000 529.4932336807251\n",
      "9 28000 519.0615953207016\n",
      "9 30000 436.9806079864502\n",
      "9 32000 543.7801613807678\n",
      "9 34000 508.0892616510391\n",
      "9 36000 468.23603773117065\n",
      "9 38000 493.35515105724335\n",
      "9 42000 518.7623333930969\n",
      "9 44000 527.2985005378723\n",
      "9 46000 459.7318651676178\n",
      "9 48000 544.3426433801651\n",
      "9 50000 457.2444406747818\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for ep in tqdm(range(10)):\n",
    "    lossK=0.0\n",
    "    for i in range(len(x_train)):\n",
    "        x= torch.LongTensor(x_train[i]).unsqueeze(0).to(device)\n",
    "        dummy_y  =[]\n",
    "        added_flg = 0\n",
    "        \n",
    "        # 同率１位は、先のほうにする。\n",
    "        for index, yy in enumerate(y_train[i][1:-1].split(\",\")):\n",
    "            if \"1\" in yy and added_flg == 0:\n",
    "                dummy_y.append(index)\n",
    "                added_flg = 1\n",
    "            \n",
    "        y = torch.LongTensor(dummy_y).to(device)\n",
    "        out = net(x)\n",
    "#         print(\"out:\", out.size(), \"y:\", y.size())\n",
    "        \n",
    "        loss = criterion(out, y)\n",
    "        lossK += loss.item()\n",
    "        \n",
    "        if (i % 2000 == 0 ):\n",
    "            print(ep, i, lossK)\n",
    "            lossK = 0.0\n",
    "        elif (i>50000):\n",
    "            break\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    outfile = \"doccls - \"+ str(ep) + \".model\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), outfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_num, ok =0, 0\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(len(x_test)):\n",
    "        x = torch.LongTensor(x_test[i]).unsqueeze(0).to(device)\n",
    "        ans =  net(x)\n",
    "        ans1 = torch.argmax(ans,dim=1).item()\n",
    "        \n",
    "        if (ans1 == np.argmax( [int(a) for a in y_test[i][1:-1].split(\",\")])+1):\n",
    "            ok += 1\n",
    "        real_data_num += 1\n",
    "print(ok, real_data_num, ok/real_data_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f1a67bc9c93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "torch.argmax(y_test[0],dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.argmax(y_test[3])\n",
    "type(y_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 0, 0, 0, 1]'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(ans,dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(a) for a in  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i**2 for i in range(5)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
