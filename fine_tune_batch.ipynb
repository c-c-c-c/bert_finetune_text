{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from icecream import ic\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese\") # 東北大のものが、mecabでtknzされている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer # transformersに入ってるものと同じ\n",
    "tknz = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test = [],[]\n",
    "# y_train, y_test = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"../data/train_twitterJSA_data.csv\")\n",
    "\n",
    "# test_df = pd.read_csv(\"../data/test_twitterJSA_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = train_df[\"label\"].tolist()\n",
    "# y_test = test_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in tqdm(range(len(train_df))):\n",
    "# #     print(ind)\n",
    "    \n",
    "#     if type(train_df[\"text\"].iloc[ind]  ) != str:\n",
    "#         continue\n",
    "#     tid = tknz.encode(train_df[\"text\"].iloc[ind]) \n",
    "    \n",
    "#     if (len(tid)>512):\n",
    "#         tid = tid[:512]\n",
    "#     x_train.append(tid)\n",
    "#     y_train.append(train_df[\"label\"].iloc[ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(x_train)):\n",
    "#     if (len(x_train[i])) < 2:\n",
    "#         print(x_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in tqdm(range(len(test_df))):\n",
    "    \n",
    "#     if type(test_df[\"text\"].iloc[ind]  ) != str:\n",
    "#         continue\n",
    "#     tid = tknz.encode(test_df[\"text\"].iloc[ind]) \n",
    "#     if (len(tid)>512):\n",
    "#         tid = tid[:512]\n",
    "#     x_test.append(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in tqdm(range(len(test_df))):\n",
    "    \n",
    "#     if type(test_df[\"text\"].iloc[ind] ) != str:\n",
    "#         continue\n",
    "    \n",
    "#     tid = tknz.encode(test_df[\"text\"].iloc[ind]) \n",
    "#     if (len(tid)>512):\n",
    "#         tid = tid[:512]\n",
    "#     x_test.append(tid)\n",
    "#     y_test.append(test_df[\"label\"].iloc[ind])\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pickle\n",
    "\n",
    "# with open ('x_train.pkl', 'bw') as fw1:\n",
    "#     pickle.dump( x_train, fw1)\n",
    "    \n",
    "# # with open ('y_train.pkl', 'bw') as fw2:\n",
    "# #     pickle.dump( y_train, fw2)\n",
    "\n",
    "# # with open ('x_test.pkl', 'bw') as fw3:\n",
    "# #     pickle.dump( x_test, fw3)\n",
    "\n",
    "# # with open ('y_test.pkl', 'bw') as fw4:\n",
    "# #     pickle.dump( y_test, fw4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('x_train.pkl','br') as fr:\n",
    "    x_train = pickle.load(fr)\n",
    "\n",
    "with open('y_train.pkl','br') as fr:\n",
    "    y_train = pickle.load(fr)\n",
    "    \n",
    "with open('x_test.pkl','br') as fr:\n",
    "    x_test = pickle.load(fr)\n",
    "\n",
    "with open('y_test.pkl','br') as fr:\n",
    "    y_test = pickle.load(fr)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, xdata, ydata):\n",
    "        self.data = xdata\n",
    "        self.label = ydata\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.label[idx]\n",
    "        return (x,y)\n",
    "\n",
    "def my_collate_fn(batch):\n",
    "    images, targets= list(zip(*batch))\n",
    "    xs = list(images)\n",
    "    ys = list(targets)\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = MyDataset(x_train,y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=True, collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocCls(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(DocCls, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.cls = nn.Linear(768, 5)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        bout = self.bert(input_ids=x1, attention_mask=x2)\n",
    "        bs = len(bout[0])\n",
    "        h0 = [bout[0][i][0] for i in range(bs)]\n",
    "        h0 = torch.stack(h0, dim=0)\n",
    "        return self.cls(h0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "net = DocCls(bert)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d2193968a540e3a1aac8a2d3704bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.6190744638442993\n",
      "0 500 238.41799189150333\n",
      "0 1000 183.2346609607339\n",
      "0 1500 180.07074964046478\n",
      "0 2000 168.58060909062624\n",
      "0 2500 158.8119985088706\n",
      "0 3000 157.84819432348013\n",
      "0 3500 159.41249015927315\n",
      "0 4000 157.2271561101079\n",
      "0 4500 146.77713668346405\n",
      "0 5000 149.88358212262392\n",
      "0 5500 140.57462050765753\n",
      "0 6000 141.90834756940603\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for ep in tqdm(range(3)):\n",
    "    i, lossK=0 ,0.0\n",
    "    for xs, ys in dataloader:\n",
    "        xsl, xmsk = [], []\n",
    "        for k in range(len(xs)):\n",
    "            tid = xs[k]\n",
    "            xsl.append(torch.LongTensor(tid))\n",
    "            xmsk.append(torch.LongTensor([1]*len(tid)))\n",
    "        \n",
    "        xsl = pad_sequence(xsl, batch_first = True).to(device)\n",
    "        xmsk = pad_sequence(xmsk, batch_first = True).to(device)\n",
    "        outputs = net(xsl, xmsk) \n",
    "                        \n",
    "        dummy_y  =[]\n",
    "\n",
    "        # 同率１位は、先のほうにする。\n",
    "                        \n",
    "        for tmp_y in ys:\n",
    "            added_flg = 0\n",
    "            for index, yy in enumerate(tmp_y[1:-1].split(\",\")):\n",
    "                if \"1\" in yy and added_flg == 0:\n",
    "                    dummy_y.append(index)\n",
    "                    added_flg = 1\n",
    "\n",
    "        ys = torch.LongTensor(dummy_y).to(device)\n",
    "    #         print(\"out:\", out.size(), \"y:\", y.size())\n",
    "\n",
    "        loss = criterion(outputs, ys)\n",
    "        lossK += loss.item()\n",
    "\n",
    "        if (i % 500 == 0 ):\n",
    "            print(ep, i, lossK)\n",
    "            lossK = 0.0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i+=1\n",
    "    outfile = \"doccls - \"+ str(ep) + \".model\"\n",
    "    torch.save(net.state_dict(),outfile)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 10\n",
    "test_dataset = MyDataset(x_test,y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_num, ok =0, 0\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for xs, ys in test_dataloader:\n",
    "        xsl, xmsk = [], []\n",
    "        for k in range(len(xs)):\n",
    "            tid = xs[k]\n",
    "            xsl.append(torch.LongTensor(tid))\n",
    "            xmsk.append(torch.LongTensor([1]*len(tid)))\n",
    "        \n",
    "        xsl = pad_sequence(xsl, batch_first = True).to(device)\n",
    "        xmsk = pad_sequence(xmsk, batch_first = True).to(device)\n",
    "        preds = net(xsl, xmsk) \n",
    "                        \n",
    "        dummy_y  =[]\n",
    "\n",
    "        # 同率１位は、先のほうにする。\n",
    "        for index_in_batch,tmp_y in enumerate(ys):\n",
    "            added_flg = 0\n",
    "            for index, yy in enumerate(tmp_y[1:-1].split(\",\")):\n",
    "                if \"1\" in yy and added_flg == 0:\n",
    "                    dummy_y.append(index)\n",
    "                    added_flg = 1\n",
    "            \n",
    "            tmp_pred = torch.argmax(preds, dim=0).item()\n",
    "            if tmp_pred == dummy_y[index_in_batch]:\n",
    "                ok +=1\n",
    "            real_data_num +=1\n",
    "    \n",
    "    for i in range(len(x_test)):\n",
    "        x = torch.LongTensor(x_test[i].unsqueeze(0).to(device))\n",
    "        ans =  net(x)\n",
    "        ans1 = torch.argmax(ans,dim=1).item()\n",
    "        if (ans1 == y_test[i]):\n",
    "            ok += 1\n",
    "        real_data_num += 1\n",
    "print(ok, read_data_num, ok/real_data_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
