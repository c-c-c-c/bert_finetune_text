{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import\n",
    "import torch\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "# 標準使用ライブラリー\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import os\n",
    "import shutil\n",
    "from icecream import ic\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# 追記\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained(\"cl-tohoku/bert-base-japanese\") # 東北大のものが、mecabでtknzされている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertJapaneseTokenizer # transformersに入ってるものと同じ\n",
    "tknz = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test = [],[]\n",
    "# y_train, y_test = [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"../data/train_twitterJSA_data.csv\")\n",
    "\n",
    "# test_df = pd.read_csv(\"../data/test_twitterJSA_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = train_df[\"label\"].tolist()\n",
    "# y_test = test_df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in tqdm(range(len(train_df))):\n",
    "# #     print(ind)\n",
    "    \n",
    "#     if type(train_df[\"text\"].iloc[ind]  ) != str:\n",
    "#         continue\n",
    "#     tid = tknz.encode(train_df[\"text\"].iloc[ind]) \n",
    "    \n",
    "#     if (len(tid)>512):\n",
    "#         tid = tid[:512]\n",
    "#     x_train.append(tid)\n",
    "#     y_train.append(train_df[\"label\"].iloc[ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(x_train)):\n",
    "#     if (len(x_train[i])) < 2:\n",
    "#         print(x_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in tqdm(range(len(test_df))):\n",
    "    \n",
    "#     if type(test_df[\"text\"].iloc[ind]  ) != str:\n",
    "#         continue\n",
    "#     tid = tknz.encode(test_df[\"text\"].iloc[ind]) \n",
    "#     if (len(tid)>512):\n",
    "#         tid = tid[:512]\n",
    "#     x_test.append(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind in tqdm(range(len(test_df))):\n",
    "    \n",
    "#     if type(test_df[\"text\"].iloc[ind] ) != str:\n",
    "#         continue\n",
    "    \n",
    "#     tid = tknz.encode(test_df[\"text\"].iloc[ind]) \n",
    "#     if (len(tid)>512):\n",
    "#         tid = tid[:512]\n",
    "#     x_test.append(tid)\n",
    "#     y_test.append(test_df[\"label\"].iloc[ind])\n",
    "# #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import pickle\n",
    "\n",
    "# with open ('x_train.pkl', 'bw') as fw1:\n",
    "#     pickle.dump( x_train, fw1)\n",
    "    \n",
    "# # with open ('y_train.pkl', 'bw') as fw2:\n",
    "# #     pickle.dump( y_train, fw2)\n",
    "\n",
    "# # with open ('x_test.pkl', 'bw') as fw3:\n",
    "# #     pickle.dump( x_test, fw3)\n",
    "\n",
    "# # with open ('y_test.pkl', 'bw') as fw4:\n",
    "# #     pickle.dump( y_test, fw4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('x_train.pkl','br') as fr:\n",
    "    x_train = pickle.load(fr)\n",
    "\n",
    "with open('y_train.pkl','br') as fr:\n",
    "    y_train = pickle.load(fr)\n",
    "    \n",
    "with open('x_test.pkl','br') as fr:\n",
    "    x_test = pickle.load(fr)\n",
    "\n",
    "with open('y_test.pkl','br') as fr:\n",
    "    y_test = pickle.load(fr)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, xdata, ydata):\n",
    "        self.data = xdata\n",
    "        self.label = ydata\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        y = self.label[idx]\n",
    "        return (x,y)\n",
    "\n",
    "def my_collate_fn(batch):\n",
    "    images, targets= list(zip(*batch))\n",
    "    xs = list(images)\n",
    "    ys = list(targets)\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = MyDataset(x_train,y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=True, collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocCls(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(DocCls, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.cls = nn.Linear(768, 5)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        bout = self.bert(input_ids=x1, attention_mask=x2)\n",
    "        bs = len(bout[0])\n",
    "        h0 = [bout[0][i][0] for i in range(bs)]\n",
    "        h0 = torch.stack(h0, dim=0)\n",
    "        return self.cls(h0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "net = DocCls(bert)\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d2193968a540e3a1aac8a2d3704bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1.6190744638442993\n",
      "0 500 238.41799189150333\n",
      "0 1000 183.2346609607339\n",
      "0 1500 180.07074964046478\n",
      "0 2000 168.58060909062624\n",
      "0 2500 158.8119985088706\n",
      "0 3000 157.84819432348013\n",
      "0 3500 159.41249015927315\n",
      "0 4000 157.2271561101079\n",
      "0 4500 146.77713668346405\n",
      "0 5000 149.88358212262392\n",
      "0 5500 140.57462050765753\n",
      "0 6000 141.90834756940603\n",
      "0 6500 142.60758792608976\n",
      "0 7000 140.3006501123309\n",
      "0 7500 138.54248748719692\n",
      "0 9000 133.006272777915\n",
      "0 9500 136.50197353214025\n",
      "0 10000 127.67729250341654\n",
      "0 10500 124.34440023452044\n",
      "0 11000 127.10077168047428\n",
      "0 11500 128.07076889276505\n",
      "0 12000 132.4112427458167\n",
      "0 12500 131.56163384765387\n",
      "0 13000 130.56636717915535\n",
      "0 13500 122.0913502573967\n",
      "0 14000 132.85614354163408\n",
      "0 14500 127.12764912843704\n",
      "0 15000 123.48361396044493\n",
      "0 15500 126.36085746437311\n",
      "0 16000 127.16237843036652\n",
      "0 16500 125.77148735523224\n",
      "0 17000 126.55256382375956\n",
      "0 17500 124.25002554059029\n",
      "0 18000 124.27455577254295\n",
      "0 18500 122.29880407452583\n",
      "0 19000 123.43393636494875\n",
      "0 19500 125.01786310970783\n",
      "0 20000 127.20127957314253\n",
      "0 20500 125.99323008209467\n",
      "0 21000 122.33195848762989\n",
      "0 21500 122.03986205905676\n",
      "0 22000 120.51885455101728\n",
      "0 22500 122.83744037896395\n",
      "0 23000 122.9515090584755\n",
      "0 23500 117.42863622307777\n",
      "0 24000 122.66448444873095\n",
      "0 25500 124.15473595261574\n",
      "0 26000 119.16306915134192\n",
      "0 26500 120.65861108154058\n",
      "0 27000 118.02819229662418\n",
      "0 27500 119.58885992318392\n",
      "0 28000 119.53087777644396\n",
      "0 28500 126.0300964191556\n",
      "0 29000 122.18435857445002\n",
      "0 29500 113.86044965684414\n",
      "0 30000 118.14591375738382\n",
      "0 30500 120.68863037973642\n",
      "0 31000 117.82123779505491\n",
      "0 31500 114.05591344088316\n",
      "0 32000 117.89836852252483\n",
      "0 32500 126.01842380315065\n",
      "0 33000 112.78129860013723\n",
      "0 33500 118.39047678560019\n",
      "0 34000 112.45888139307499\n",
      "0 34500 112.31555593013763\n",
      "0 35000 118.64443013817072\n",
      "0 35500 115.49630618095398\n",
      "0 36000 120.74332262575626\n",
      "0 36500 120.98000545799732\n",
      "0 37000 115.07891581207514\n",
      "0 37500 118.30306704342365\n",
      "0 38000 115.93051143735647\n",
      "1 0 0.1067037433385849\n",
      "1 500 114.3505614772439\n",
      "1 1000 111.34395799040794\n",
      "1 1500 112.99158015847206\n",
      "1 2000 115.91741942614317\n",
      "1 2500 108.4284886866808\n",
      "1 3000 112.71861838549376\n",
      "1 3500 113.34204285591841\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for ep in tqdm(range(3)):\n",
    "    i, lossK=0 ,0.0\n",
    "    for xs, ys in dataloader:\n",
    "        xsl, xmsk = [], []\n",
    "        for k in range(len(xs)):\n",
    "            tid = xs[k]\n",
    "            xsl.append(torch.LongTensor(tid))\n",
    "            xmsk.append(torch.LongTensor([1]*len(tid)))\n",
    "        \n",
    "        xsl = pad_sequence(xsl, batch_first = True).to(device)\n",
    "        xmsk = pad_sequence(xmsk, batch_first = True).to(device)\n",
    "        outputs = net(xsl, xmsk) \n",
    "                        \n",
    "        dummy_y  =[]\n",
    "\n",
    "        # 同率１位は、先のほうにする。\n",
    "                        \n",
    "        for tmp_y in ys:\n",
    "            added_flg = 0\n",
    "            for index, yy in enumerate(tmp_y[1:-1].split(\",\")):\n",
    "                if \"1\" in yy and added_flg == 0:\n",
    "                    dummy_y.append(index)\n",
    "                    added_flg = 1\n",
    "\n",
    "        ys = torch.LongTensor(dummy_y).to(device)\n",
    "    #         print(\"out:\", out.size(), \"y:\", y.size())\n",
    "\n",
    "        loss = criterion(outputs, ys)\n",
    "        lossK += loss.item()\n",
    "\n",
    "        if (i % 500 == 0 ):\n",
    "            print(ep, i, lossK)\n",
    "            lossK = 0.0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i+=1\n",
    "    outfile = \"doccls - \"+ str(ep) + \".model\"\n",
    "    torch.save(net.state_dict(),outfile)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 10\n",
    "test_dataset = MyDataset(x_test,y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, collate_fn=my_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47150 61064 0.7721407048342722\n"
     ]
    }
   ],
   "source": [
    "real_data_num, ok =0, 0\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for xs, ys in test_dataloader:\n",
    "        xsl, xmsk = [], []\n",
    "        for k in range(len(xs)):\n",
    "            tid = xs[k]\n",
    "            xsl.append(torch.LongTensor(tid))\n",
    "            xmsk.append(torch.LongTensor([1]*len(tid)))\n",
    "        \n",
    "        xsl = pad_sequence(xsl, batch_first = True).to(device)\n",
    "        xmsk = pad_sequence(xmsk, batch_first = True).to(device)\n",
    "        preds = net(xsl, xmsk) \n",
    "                        \n",
    "        dummy_y  =[]\n",
    "\n",
    "        # 同率１位は、先のほうにする。\n",
    "        for index_in_batch,tmp_y in enumerate(ys):\n",
    "            added_flg = 0\n",
    "            for index, yy in enumerate(tmp_y[1:-1].split(\",\")):\n",
    "                if \"1\" in yy and added_flg == 0:\n",
    "                    dummy_y.append(index)\n",
    "                    added_flg = 1\n",
    "            \n",
    "            tmp_pred = torch.argmax(preds[index_in_batch], dim=0).item()\n",
    "            if tmp_pred == dummy_y[index_in_batch]:\n",
    "                ok +=1\n",
    "            real_data_num +=1\n",
    "\n",
    "print(ok, real_data_num, ok/real_data_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正解率77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
